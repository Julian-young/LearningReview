## 机器学习介绍

- 机器学习介绍：机器学习是什么，怎么来的，理论基础是什么，为了解决什么问题。

- 机器学习是什么?

  - 什么是“学习”？学习就是人类通过观察、积累经验，掌握某项技能或能力。就好像我们从小学 习识别字母、认识汉字，就是学习的过程。而机器学习（Machine Learning），顾名思义， 就是让机器（计算机）也能向人类一样，通过观察大量的数据和训练，发现事物规律，获得 某种分析问题、解决问题的能力。

  - Improving some performance measure with experence computed from data. 

    也就是机器从数据中总结经验，从数据中找出某种规律或者模型，并用它来解决实 际问题。
    ![image-20200106151549460](/Users/yangjiale/Library/Application Support/typora-user-images/image-20200106151549460.png)

- 为了解决什么问题
  
  - 其应用场合大致可归纳为三个条件
    - 事物本身存在某种潜在规律
    - 某些问题难以使用普通编程解决
    - 有大量的数据样本可供使用
  - ![image-20200106151620380](/Users/yangjiale/Library/Application Support/typora-user-images/image-20200106151620380.png)

## 机器学习分类

- Learning with Different Output Space Y

  - 1.分类问题，输出都是离散值
    - 二元分类（binary classification）：输出只有两个，一般y={-1, +1}
      - 包括信用卡发放、垃圾邮件判别、患者疾病诊断、答案正确性估计等
    - 多元分类（Multiclass Classification）：输出 多于两个，y={1, 2, … , K}, K>2
      - 有数字识别、图片内容识别等
  - 2.回归问题，输出y=R，即范围在整个实数空间， 是连续的
    - 线性回归
      - 预测房屋价格、股票收益多少等

- Learning with Different Data Label yn

  - 有监督：训练样本D既有输入特征x，也有输出yn

    - 二元分类、多元分类或者是回归

    - 判别模型与生成模型

  - 半监督：一部分数据有输出标签yn，而另一部分数据没有输出标签yn

  - 无监督：训练样本没有输出标签yn的

    - 聚类、异常检测

  - 强化学习：强化学习中，我们给模型或系统一些输 入，但是给不了我们希望的真实的输出y，根据模型的输出反馈，如果反馈结果良好，更接近真实输出，就给其**正向激励**，如果反馈结果不好，偏离真实输出，就给其**反向激励**。不断通过“**反馈-修正**”这种形式，一步一步让模型学习的更好，这就是强化学习的核心所在。

    - 根据用户点击、选择而不断改进的广告系统

- 按任务类型分

  - 回归

  - 分类

  - 聚类

  - 生成模型与判别模型

    - 判别模型的重点在于用差别去分类；

    - 生成模型是通过尝试知道（或者关注）数据是如何生成（就是去找到一个能够生成这些数据的分布，体现在数学上就是，找到的这个分布是一个联合分布），之后再对数据分类（体现在数学上就是用联合分算出属于某类别的条件概率，选条件概率最大的那个类别就是判断数据所属的类别）

      ![img](https://pic2.zhimg.com/80/v2-a2e753542fc6384ee351cabdbe6dd523_hd.jpg)

    - **二者目的都是在使后验概率最大化，判别式是直接对后验概率建模，但是生成模型通过贝叶斯定理这一“桥梁”使问题转化为求联合概率**

      - 判别式模型举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。
      - 生成式模型举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。

  ## 机器学习方法三要素

  - **模型**
    
    - 就是要学习的概率分布或决策函数
      所有可能的条件概率分布或者决策函数构成的集合就是模型的假设空间
    
  - **策略**
    - 从假设空间中学习最优模型的方法,称为策略
      衡量模型好与不好需要一些指标,这时引入风险函数和损失函数来衡量。预测值和真实值通常是不想等的,我们用损失函数或代价函数来度量预测错误的程度,记作 L(Y,f(x))
      - *0~1损失函数*
        $$
        L(y,f(x)) =
        \begin{cases}
        0, & \text{y = f(x)}  \\
        1, & \text{y $\neq$ f(x)}
        \end{cases}
        $$
      
      - *平方损失函数*
        $$
        L(y,f(x))=|y-f(x)|
        $$
      
      - *绝对损失函数*
        $$
        L(y,f(x))=(y-f(x))^2
        $$
      
      - *对数损失函数*
        $$
        L(y,f(x))=log(1+e^{-yf(x)})
        $$
      - *指数损失函数*
        $$
        L(y,f(x))=exp(-yf(x))
        $$
      - *Hinge损失函数*
        $$
        L(w,b)=max\{0,1-yf(x)\}
        $$
    
  - **算法**
    
    - 是指学习模型时的具体计算方法,求解最优模型归结为一个最优化问题,统计学习的算法等价于求解最优化问题的算法,也就是求解析解或数值解
      - *批量梯度下降(BGD)*
        $$
        \theta=\theta-\eta\nabla_\theta J(\theta)
        $$
      
      - *随机梯度下降法(SGD)*
        $$
        \theta=\theta-\eta\nabla_\theta J(\theta;x^{(i)},y^{(i)})
        $$
      
      - *小批量梯度下降*
        $$
        \theta=\theta-\eta\nabla_\theta J(\theta;x^{(i:i+n)},y^{(i:i+n)})
        $$
        
      - *引入动量的梯度下降*
        $$
        \begin{cases}
        v_t=\gamma v_{t-1}+\eta \nabla_\theta J(\theta)  \\
        \theta=\theta-v_t
        \end{cases}
        $$
      - *自适应学习率的Adagrad算法*
        $$
        \begin{cases}
        g_t= \nabla_\theta J(\theta)  \\
        \theta_{t+1}=\theta_{t,i}-\frac{\eta}			
        {\sqrt{G_t+\varepsilon}} \cdot g_t
        \end{cases}
        $$
    
   - **模型评估指标**

      - **R方 R square**
        
        - ![v2-66f85f9a137197d57088cc71cb7ee23f_hd](https://pic4.zhimg.com/80/v2-66f85f9a137197d57088cc71cb7ee23f_hd.png)
        - ![v2-6b255832b7b8cb2d31a9422f52f4480c_hd](https://pic1.zhimg.com/80/v2-6b255832b7b8cb2d31a9422f52f4480c_hd.jpg)
        
          - 上：y预测 - y真，our model，
          - 下：y真平均 - y真，baseline model
        
      - MSE(Mean Squared Error)
        $$
        MSE(y,f(x))=\frac{1}{N}\sum_{i=1}^{N}(y-f(x))^2
        $$
        
      - MAE(Mean Absolute Error)
        $$
        MAE(y,f(x))=\frac{1}{N}\sum_{i=1}^{N}|y-f(x)|
        $$
        
      - **RMSE(Root Mean Squard Error)**
        $$
        RMSE(y,f(x))=\frac{1}{1+MSE(y,f(x))}
        $$
        
      - **Confusion Matrix**

        - ![precision-recall-relevant-selected](https://www.kdnuggets.com/images/precision-recall-relevant-selected.jpg)
        - 真正例(True Positive, TP):You predicted positive and it’s true
        - 假负例(False Negative, FN): You predicted negative and it’s false
        - 假正例(False Positive, FP): You predicted positive and it’s false 
        - 真负例(True Negative, TN): You predicted negative and it’s true

      - **准确率(Accuracy)**

      $$
      ACC=\frac{TP+TN}{TP+FN+FP+TN}
      $$
      * **精准率(Precision)**
        * Out of all the positive classes we have predicted, how many are actually positive
      $$
      P=\frac{TP}{TP+FP}
      $$
      * **召回率(Recall/TPR/Sensitivity)**
        * Out of all the positive classes, how much we predicted correctly. It should be high as possible.
      $$
      R=\frac{TP}{TP+FN}
      $$
      * **F1-Score**
        * F-score helps to measure Recall and Precision at the same time. It uses Harmonic Mean in place of Arithmetic Mean by punishing the extreme values more.

      $$
      \frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}
      $$

      - Specificity
        $$
      	Specificity=\frac{TN}{TN+FP}
      	$$
      - FPR = 1-Specificity
        $$
      	FPR=\frac{FP}{TN+FP}
      	$$
      - **AUC - ROC Curve**
        
          - AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. 
          - ![1*pk05QGzoWhCgRiiFbz-oKQ](https://miro.medium.com/max/361/1*pk05QGzoWhCgRiiFbz-oKQ.png)
      			- <center class="half">
      <img src="https://miro.medium.com/max/528/1*Uu-t4pOotRQFoyrfqEvIEg.png" width="300"/><img src="https://miro.medium.com/max/365/1*HmVIhSKznoW8tFsCLeQjRw.png" width="170"/>
      </center>
      			- <center class="half">
        <img src="https://miro.medium.com/max/507/1*yF8hvKR9eNfqqej2JnVKzg.png" width="300"/><img src="https://miro.medium.com/max/365/1*-tPXUvvNIZDbqXP0qqYNuQ.png" width="170"/>
      </center>
      			- <center class="half">
      <img src="https://miro.medium.com/max/430/1*iLW_BrJZRI0UZSflfMrmZQ.png" width="300"/><img src="https://miro.medium.com/max/365/1*k_MPO2Q9bLNH9k4Wlk6v_g.png" width="170"/>
      </center>
      			- <center class="half">
      <img src="https://miro.medium.com/max/556/1*aUZ7H-Lw74KSucoLlj1pgw.png" width="300"/><img src="https://miro.medium.com/max/365/1*H7JGQbaa06BUab6tvGNZKg.png" width="170"/>
      </center>

  - **复杂度度量**

      - **偏差与方差**

          - **What is bias?**
              - Bias is the difference between the average prediction of our model and the correct value which we are trying to predict
          - **What is variance?**
              - Variance is the variability of model prediction for a given data point or a value which tells us spread of our data
          - ![1*BtpFTBrGaQNE3TvU-0EVSQ](https://miro.medium.com/max/290/1*BtpFTBrGaQNE3TvU-0EVSQ.png)
          - ![1*e7VaoBh5apjaM2p4afkFyg](https://miro.medium.com/max/579/1*e7VaoBh5apjaM2p4afkFyg.png)
          - ![1*xwtSpR_zg7j7zusa4IDHNQ](https://miro.medium.com/max/468/1*xwtSpR_zg7j7zusa4IDHNQ.png)
          - ![1*9hPX9pAO3jqLrzt0IE3JzA](https://miro.medium.com/max/830/1*9hPX9pAO3jqLrzt0IE3JzA.png)

      - **可避免偏差&可避免方差**

          - ![1*RQXgxVsrn406s7jBowyLkw](https://miro.medium.com/max/372/1*RQXgxVsrn406s7jBowyLkw.png)

          - ![1*SHjeJH4wFNjzxYjVVfh0fQ](https://miro.medium.com/max/439/1*SHjeJH4wFNjzxYjVVfh0fQ.png)

          - **Difference (Training Error, Human-Level Performance) = Avoidable Bias**

          - **Difference (Development Error, Training Error) = Variance**

              - **Scenario A:**

                  ​	7% > 2% -》高偏差（可避免偏差大于方差）

              - **Scenario B:**

                  ​	0.5% < 2% -》高方差（可避免偏差小于方差）

      - **过拟合与欠拟合**

          - ![1*RQ6ICt_FBSx6mkAsGVwx8g](https://miro.medium.com/max/562/1*RQ6ICt_FBSx6mkAsGVwx8g.png)
              - **欠拟合**一般表示模型对数据的表现能力不足，通常是模型的复杂度不够，并且Bias高，训练集的损失值高，测试集的损失值也高.
              - **过拟合**一般表示模型对数据的表现能力过好，通常是模型的复杂度过高，并且Variance高，训练集的损失值低，测试集的损失值高.

      - **结构风险与经验风险**

          - *经验风险*：是对训练集中的所有样本点损失函数的平均最小化
              - 经验风险越小说明模型f(X)对训练集的拟合程度越好
          - *期望风险*：
              - 未知的样本数据（<X,Y>）的数量是不容易确定的，所以就没有办法用所有样本损失函数的平均值的最小化这个方法，那么怎么来衡量这个模型对所有的样本（包含未知的样本和已知的训练样本）预测能力呢？熟悉概率论的很容易就想到了用期望。
              - 经验风险是局部的，基于训练集所有样本点损失函数最小化的。
              - 期望风险是全局的，是基于所有样本点的损失函数最小化的。
          - *结构风险*：
              - 只考虑经验风险的话，会出现过拟合的现象，过拟合的极端情况便是模型f(x)对训练集中所有的样本点都有最好的预测能力，但是对于非训练集中的样本数据，模型的预测能力非常不好。怎么办呢？这个时候就引出了结构风险。结构风险是对经验风险和期望风险的折中。在经验风险函数后面加一个正则化项（惩罚项）便是结构风险了。

      - **泛化能力**

          - 泛化能力通俗来讲就是指学习到的模型对未知数据的预测能力
          - 提高泛化能力的方式大致有三种：1.增加数据量。2.正则化。3.凸优化。