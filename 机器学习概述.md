## 机器学习介绍

- 机器学习介绍：机器学习是什么，怎么来的，理论基础是什么，为了解决什么问题。

- 机器学习是什么?

  - 什么是“学习”？学习就是人类通过观察、积累经验，掌握某项技能或能力。就好像我们从小学 习识别字母、认识汉字，就是学习的过程。而机器学习（Machine Learning），顾名思义， 就是让机器（计算机）也能向人类一样，通过观察大量的数据和训练，发现事物规律，获得 某种分析问题、解决问题的能力。

  - Improving some performance measure with experence computed from data. 

    也就是机器从数据中总结经验，从数据中找出某种规律或者模型，并用它来解决实 际问题。
    ![image-20200106151549460](/Users/yangjiale/Library/Application Support/typora-user-images/image-20200106151549460.png)

- 为了解决什么问题
  
  - 其应用场合大致可归纳为三个条件
    - 事物本身存在某种潜在规律
    - 某些问题难以使用普通编程解决
    - 有大量的数据样本可供使用
  - ![image-20200106151620380](/Users/yangjiale/Library/Application Support/typora-user-images/image-20200106151620380.png)

## 机器学习分类

- Learning with Different Output Space Y

  - 1.分类问题，输出都是离散值
    - 二元分类（binary classification）：输出只有两个，一般y={-1, +1}
      - 包括信用卡发放、垃圾邮件判别、患者疾病诊断、答案正确性估计等
    - 多元分类（Multiclass Classification）：输出 多于两个，y={1, 2, … , K}, K>2
      - 有数字识别、图片内容识别等
  - 2.回归问题，输出y=R，即范围在整个实数空间， 是连续的
    - 线性回归
      - 预测房屋价格、股票收益多少等

- Learning with Different Data Label yn

  - 有监督：训练样本D既有输入特征x，也有输出yn

    - 二元分类、多元分类或者是回归

    - 判别模型与生成模型

  - 半监督：一部分数据有输出标签yn，而另一部分数据没有输出标签yn

  - 无监督：训练样本没有输出标签yn的

    - 聚类、异常检测

  - 强化学习：强化学习中，我们给模型或系统一些输 入，但是给不了我们希望的真实的输出y，根据模型的输出反馈，如果反馈结果良好，更接近真实输出，就给其**正向激励**，如果反馈结果不好，偏离真实输出，就给其**反向激励**。不断通过“**反馈-修正**”这种形式，一步一步让模型学习的更好，这就是强化学习的核心所在。

    - 根据用户点击、选择而不断改进的广告系统

- 按任务类型分

  - 回归
  
  - 分类
  
  - 聚类
  
  - 生成模型与判别模型
  
    - 判别模型的重点在于用差别去分类；
  
    - 生成模型是通过尝试知道（或者关注）数据是如何生成（就是去找到一个能够生成这些数据的分布，体现在数学上就是，找到的这个分布是一个联合分布），之后再对数据分类（体现在数学上就是用联合分算出属于某类别的条件概率，选条件概率最大的那个类别就是判断数据所属的类别）
  
      ![img](https://pic2.zhimg.com/80/v2-a2e753542fc6384ee351cabdbe6dd523_hd.jpg)
  
    - **二者目的都是在使后验概率最大化，判别式是直接对后验概率建模，但是生成模型通过贝叶斯定理这一“桥梁”使问题转化为求联合概率**
  
      - 判别式模型举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。
      - 生成式模型举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。
  
  ## 机器学习方法三要素
  
  - **模型**
    - 就是要学习的概率分布或决策函数
      所有可能的条件概率分布或者决策函数构成的集合就是模型的假设空间
    
  - **策略**
    - 从假设空间中学习最优模型的方法,称为策略
      衡量模型好与不好需要一些指标,这时引入风险函数和损失函数来衡量。预测值和真实值通常是不想等的,我们用损失函数或代价函数来度量预测错误的程度,记作 L(Y,f(x))
      - *0~1损失函数*
        $$
        L(y,f(x)) =
        \begin{cases}
        0, & \text{y = f(x)}  \\
        1, & \text{y $\neq$ f(x)}
        \end{cases}
        $$
      
      - *平方损失函数*
        $$
        L(y,f(x))=|y-f(x)|
        $$
      
      - *绝对损失函数*
        $$
        L(y,f(x))=(y-f(x))^2
        $$
      
      - *对数损失函数*
        $$
        L(y,f(x))=log(1+e^{-yf(x)})
        $$
      - *指数损失函数*
        $$
        L(y,f(x))=exp(-yf(x))
        $$
      - *Hinge损失函数*
        $$
        L(w,b)=max\{0,1-yf(x)\}
        $$
    
  - **算法**
    
    - 是指学习模型时的具体计算方法,求解最优模型归结为一个最优化问题,统计学习的算法等价于求解最优化问题的算法,也就是求解析解或数值解
      - *批量梯度下降(BGD)*
        $$
        \theta=\theta-\eta\nabla_\theta J(\theta)
        $$
      
      - *随机梯度下降法(SGD)*
        $$
        \theta=\theta-\eta\nabla_\theta J(\theta;x^{(i)},y^{(i)})
        $$
      
      - *小批量梯度下降*
        $$
        \theta=\theta-\eta\nabla_\theta J(\theta;x^{(i:i+n)},y^{(i:i+n)})
        $$
        
      - *引入动量的梯度下降*
        $$
        \begin{cases}
        v_t=\gamma v_{t-1}+\eta \nabla_\theta J(\theta)  \\
        \theta=\theta-v_t
        \end{cases}
        $$
      - *自适应学习率的Adagrad算法*
        $$
        \begin{cases}
        g_t= \nabla_\theta J(\theta)  \\
        \theta_{t+1}=\theta_{t,i}-\frac{\eta}			
        {\sqrt{G_t+\varepsilon}} \cdot g_t
        \end{cases}
        $$
    
   - 模型评估指标
  
      - 